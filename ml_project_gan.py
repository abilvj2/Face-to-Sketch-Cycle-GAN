# -*- coding: utf-8 -*-
"""ML_Project_GAN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1k97fuIpwyUlY8mkpWUGYooq3rNOmhTab
"""

from google.colab import drive
drive.mount('/content/drive')
#COde to mount source, ignore

import os
import cv2
import numpy as np
import tensorflow as tf
from sklearn.model_selection import train_test_split
from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, Conv2DTranspose, Flatten, Dense
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt

# Function to generate and save images
def generate_and_save_images(generator, epoch, examples=10, dim=(1, 10), figsize=(10, 1)):
    generated_images = generator.predict(get_batch(X_val, examples))
    generated_images = generated_images * 0.5 + 0.5

    fig = plt.figure(figsize=figsize)
    for i in range(examples):
        plt.subplot(dim[0], dim[1], i + 1)
        plt.imshow(generated_images[i, :, :, 0], cmap='gray')
        plt.axis('off')

    plt.tight_layout()
    plt.savefig(f"gan_generated_image_epoch_{epoch}.png")
    plt.show()

# Define the generator network
def build_generator(input_shape):
    input_image = Input(shape=input_shape)
    x = Conv2D(64, (3, 3), padding='same')(input_image)
    x = BatchNormalization()(x)
    x = Activation('relu')(x)
    # Add more encoder layers...

    x = Conv2DTranspose(64, (3, 3), padding='same')(x)
    x = BatchNormalization()(x)
    x = Activation('relu')(x)
    # Add more decoder layers...

    # Modify the output layer to generate (128, 128, 1) images
    output_image = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)
    return Model(input_image, output_image)

# Define the discriminator network
def build_discriminator(input_shape):
    input_image = Input(shape=input_shape)
    x = Conv2D(64, (3, 3), padding='same')(input_image)
    x = BatchNormalization()(x)
    x = Activation('relu')(x)
    # Add more discriminator layers...

    x = Flatten()(x)
    output = Dense(1, activation='sigmoid')(x)
    return Model(input_image, output)

# Define the GAN model
def build_gan(generator, discriminator, input_shape):
    discriminator.trainable = False
    gan_input = Input(shape=input_shape)
    gan_output = discriminator(generator(gan_input))
    gan_model = Model(gan_input, gan_output)
    gan_model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5))
    return gan_model

def preprocessing_face_blur(image):
    # Resize the image to (128, 128) and convert to grayscale
    image = cv2.resize(image, (128, 128))
    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    # Apply Gaussian blur and scale to [0, 1]
    return cv2.divide(255 - cv2.GaussianBlur(cv2.bitwise_not(image), (21, 21), sigmaX=0, sigmaY=0), 255, scale=256)

# Define paths and directories
data_path = '/content/drive/MyDrive/Colab Notebooks/ML_Project/photo'
blurimage_path = '/content/drive/MyDrive/Colab Notebooks/ML_Project/output'

# Create directories
os.makedirs(blurimage_path, exist_ok=True)

# Preprocess and copy images
faceimage_folder = []
output_folder = []
for file in os.listdir(data_path):
    if file.endswith((".jpg", ".png", ".jpeg")):
        img = cv2.imread(os.path.join(data_path, file))
        preprocessed_img = preprocessing_face_blur(img)
        cv2.imwrite(os.path.join(blurimage_path, file), preprocessed_img)
        faceimage_folder.append(os.path.join(data_path, file))
        output_folder.append(os.path.join(blurimage_path, file))

# Split data into train, validation, and test sets
X_train, X_temp, y_train, y_temp = train_test_split(faceimage_folder, output_folder, test_size=0.3, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

# Function to get a batch of training data
def get_batch(data, batch_size):
    indices = np.arange(len(data))
    np.random.shuffle(indices)

    for i in range(0, len(data), batch_size):
        batch_indices = indices[i:i + batch_size]
        batch_X = [data[idx] for idx in batch_indices]
        batch_y = [y_train[idx] for idx in batch_indices]

        batch_X_images = [cv2.imread(img_path) for img_path in batch_X]
        batch_X_images = [preprocessing_face_blur(img) for img in batch_X_images]
        batch_X_images = np.expand_dims(np.array(batch_X_images), axis=-1)  # Ensure the shape is (batch_size, 128, 128, 1)

        batch_y_images = [cv2.imread(img_path) for img_path in batch_y]
        batch_y_images = [preprocessing_face_blur(img) for img in batch_y_images]
        batch_y_images = np.expand_dims(np.array(batch_y_images), axis=-1)  # Ensure the shape is (batch_size, 128, 128, 1)

        yield batch_X_images, batch_y_images

# ... (rest of the code remains the same)

# Define input image dimensions and other hyperparameters
input_shape = (128, 128, 1)
#batch_size = 64
batch_size = 32

#epochs = 10000
epochs = 100

# Build and compile the models
generator = build_generator(input_shape)
discriminator = build_discriminator(input_shape)
gan = build_gan(generator, discriminator, input_shape)

# Compile the discriminator model
discriminator.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.0002, beta_1=0.5))

# Compile the generator model (if not already compiled)
generator.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=0.0002, beta_1=0.5))

# Compile the GAN model
gan.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.0002, beta_1=0.5))

# Training loop
for epoch in range(epochs):
    for _ in range(len(X_train) // batch_size):
        real_images, sketch_images = next(get_batch(X_train, batch_size))
        real_labels = np.ones((batch_size, 1))
        d_loss_real = discriminator.train_on_batch(sketch_images, real_labels)

        fake_images = generator.predict(real_images)
        fake_labels = np.zeros((batch_size, 1))
        d_loss_fake = discriminator.train_on_batch(fake_images, fake_labels)

        gan_labels = np.ones((batch_size, 1))
        g_loss = gan.train_on_batch(real_images, gan_labels)

    # Print loss and save generated images
    print(f"Epoch {epoch + 1}, D Loss Real: {d_loss_real}, D Loss Fake: {d_loss_fake}, G Loss: {g_loss}")

    if (epoch + 1) % 100 == 0:
        generate_and_save_images(generator, epoch + 1)

"""**Shared space for editing and optimising code**"""

def train_step(images):
    noise = tf.random.normal([BATCH_SIZE, 100])

    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:
        generated_images = generator(noise, training=True)

        real_output = discriminator(images, training=True)
        fake_output = discriminator(generated_images, training=True)

        gen_loss = generator_loss(fake_output)
        disc_loss = discriminator_loss(real_output, fake_output)

    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)
    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)

    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))
    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))

#Generic code with change in parameters

# Generator model
def build_generator():
    model = tf.keras.Sequential()
    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())

    model.add(layers.Reshape((7, 7, 256)))
    assert model.output_shape == (None, 7, 7, 256)

    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))
    assert model.output_shape == (None, 7, 7, 128)
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())

    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))
    assert model.output_shape == (None, 14, 14, 64)
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())

    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))
    assert model.output_shape == (None, 28, 28, 1)

    return model

# Discriminator model
def build_discriminator():
    model = tf.keras.Sequential()
    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',
                                     input_shape=[28, 28, 1]))
    model.add(layers.LeakyReLU())
    model.add(layers.Dropout(0.3))

    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))
    model.add(layers.LeakyReLU())
    model.add(layers.Dropout(0.3))

    model.add(layers.Flatten())
    model.add(layers.Dense(1))

    return model

# Define loss functions
cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)

def discriminator_loss(real_output, fake_output):
    real_loss = cross_entropy(tf.ones_like(real_output), real_output)
    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)
    total_loss = real_loss + fake_loss
    return total_loss

def generator_loss(fake_output):
    return cross_entropy(tf.ones_like(fake_output), fake_output)

# Define optimizers
generator_optimizer = tf.keras.optimizers.Adam(1e-4)
discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)

# Create generator and discriminator
generator = build_generator()
discriminator = build_discriminator()